from FinMind.data import DataLoader
import pandas as pd
import os
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from pathlib import Path
import sys
from scipy import stats

### python momentumNew.py >> terminal_log.txt 2>&1
sys.stdout.reconfigure(encoding='utf-8')

### ç­–ç•¥åƒæ•¸è¨­å®š
sDt = datetime.strptime('2010/01/01', "%Y/%m/%d") # Start Date
eDt = datetime.strptime('2020/12/31', "%Y/%m/%d") # End Date
oPeriod = 3 # Observer Period
hPeriod = 3 # Holding Period
planType = "A" # A 

# ### FinMind apiè¨­å®š
# apiUrl = "https://api.finmindtrade.com/api/v4/data"
# api = DataLoader()
# token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkYXRlIjoiMjAyNS0wNi0yOCAxNToyODoxMSIsInVzZXJfaWQiOiJueWN1bGFiNjE1IiwiaXAiOiIxMTQuMTM3LjIxOS4yMTEiLCJleHAiOjE3NTE3MDA0OTF9.u4s5jxRFBz2ojJ01n-8c6Jm2G0FAhtn1-gSMsaspZWE"
# api.login_by_token(api_token=token)

# ### æ’ˆå–å¸‚å€¼è³‡æ–™  => DONE
# outputDir = r'..\data\FinMind\TW\MarketValue'

# ## å–å¾—ä¸Šå¸‚è‚¡ç¥¨åˆ—è¡¨ (create by finTwseList.py)
# stockListSrc = f"../data/analysis/summary/taiwan_stock_info-twse.csv" 
# dfSI = pd.read_csv(stockListSrc)
# stockList = dfSI['stock_id'].drop_duplicates().tolist()
# print("ğŸ“¢ å³å°‡æ’ˆå–[å¸‚å€¼æ­·å²]è³‡æ–™ï¼Œè‚¡ç¥¨æ¸…å–®çš„é•·åº¦ç‚ºï¼š", len(stockList))

# for stock_id in stockList:
#     outputFile = f'{outputDir}/{sDt.strftime("%Y%m%d")}-{eDt.strftime("%Y%m%d")}/TWMV-{stock_id}.csv'
#     if os.path.exists(outputFile):
#         print("â˜‘ï¸ æª”æ¡ˆå·²å­˜åœ¨ï¼š", outputFile)
#     else:
#         os.makedirs(os.path.dirname(outputFile), exist_ok=True) # ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
#         dfMV = api.taiwan_stock_market_value(
#             stock_id=stock_id,
#             start_date=sDt.strftime("%Y-%m-%d"),
#             end_date=eDt.strftime("%Y-%m-%d")
#         )
#         dfMV.to_csv(outputFile, index=False, encoding='utf-8-sig')
#         print("âœ… æª”æ¡ˆå­˜å–æˆåŠŸï¼š", outputFile)


# ### ç®—å‡ºæ¯å€‹æœˆå„è‚¡ç¥¨çš„å¹³å‡å¸‚å€¼
# outputDir = r'..\data\analysis\summary'
# outputPath = f'{outputDir}/TWMV_mean-{sDt.strftime("%Y%m")}_{eDt.strftime("%Y%m")}.csv'
# if os.path.exists(outputPath):
#     dfTWMVmean = pd.read_csv(outputPath)
#     print("â˜‘ï¸ æª”æ¡ˆå·²å­˜åœ¨ï¼š", outputPath)    
# else:
#     # è³‡æ–™å¤¾è·¯å¾‘
#     marketValDataDir = f'../data/FinMind/TW/MarketValue/{sDt.strftime("%Y%m%d")}-{eDt.strftime("%Y%m%d")}'
#     marketValFolder = Path(marketValDataDir)

#     # æ‰¾åˆ°æ‰€æœ‰ CSV æª”æ¡ˆ
#     TWMVfiles = list(marketValFolder.glob('*.csv'))
#     print("æ‰¾åˆ°çš„æª”æ¡ˆï¼š", TWMVfiles)

#     # å­˜æ”¾æ‰€æœ‰æª”æ¡ˆçš„çµæœ
#     marketValMeans = []

#     for aTWMVfile in TWMVfiles:
#         # æª¢æŸ¥æª”æ¡ˆå¤§å°
#         if aTWMVfile.stat().st_size == 0:
#             print(f"æª”æ¡ˆ {aTWMVfile} æ˜¯ç©ºçš„ï¼Œè·³é")
#             continue

#         # è®€å…¥è³‡æ–™
#         try:
#             dfTWMVmean = pd.read_csv(aTWMVfile)
#         except pd.errors.EmptyDataError:
#             print(f"æª”æ¡ˆ {aTWMVfile} ç„¡è³‡æ–™ï¼Œè·³é")
#             continue

#         if dfTWMVmean.empty:
#             print(f"æª”æ¡ˆ {aTWMVfile} å…§å®¹ç‚ºç©ºï¼Œè·³é")
#             continue

#         if 'market_value' not in dfTWMVmean.columns:
#             print(f"æª”æ¡ˆ {aTWMVfile} ç¼ºå°‘ market_value æ¬„ä½ï¼Œè·³é")
#             continue
            
#         # æ’é™¤ market_value == 0
#         dfTWMVmean = dfTWMVmean[dfTWMVmean['market_value'] != 0]
        
#         # è½‰æˆ datetime
#         dfTWMVmean['date'] = pd.to_datetime(dfTWMVmean['date'])
        
#         # ç”¢ç”Ÿ year_month æ¬„ä½ (YYYY-MM)
#         dfTWMVmean['year_month'] = dfTWMVmean['date'].dt.strftime('%Y-%m')
        
#         # ä»¥ year_month åˆ†çµ„è¨ˆç®—å¹³å‡
#         grouped = dfTWMVmean.groupby('year_month')['market_value'].mean().reset_index()
        
#         # åŠ ä¸Š stock_id (æ¯æª”è³‡æ–™éƒ½æ˜¯åŒä¸€å€‹ stock_id)
#         stock_id = dfTWMVmean['stock_id'].iloc[0]
#         grouped['stock_id'] = stock_id
        
#         # æ”¹æ¬„ä½é †åº
#         grouped = grouped[['stock_id', 'year_month', 'market_value']]
        
#         # æ”¹æ¬„ä½åç¨±
#         grouped = grouped.rename(columns={'market_value': 'mean_market_value'})
        
#         # åŠ åˆ°ç¸½è¡¨
#         marketValMeans.append(grouped)

#     # åˆä½µæ‰€æœ‰çµæœ
#     dfTWMVmean = pd.concat(marketValMeans, ignore_index=True)

#     # ä¾ year_month åˆ†çµ„ï¼Œè¨ˆç®—æ’å (1=æœ€å¤§)
#     dfTWMVmean['rank'] = dfTWMVmean.groupby('year_month')['mean_market_value'] \
#                 .rank(method='min', ascending=False)

#     # è¼¸å‡ºå«æ’åçš„å®Œæ•´è³‡æ–™
#     dfTWMVmean.to_csv(outputPath, index=False, encoding='utf-8')

#     # è¼¸å‡ºæˆCSV
#     dfTWMVmean.to_csv(outputPath, index=False, encoding='utf-8')
#     print("âœ… æª”æ¡ˆå­˜å–æˆåŠŸï¼š", outputPath)

# ### å–å‡ºæ¯å€‹æœˆå‰nå¤§å¸‚å€¼çš„åå–®
# maxIncludeRank = 200
# outputPath = f'{outputDir}/TWMV_mean-{sDt.strftime("%Y%m")}_{eDt.strftime("%Y%m")}-rank{maxIncludeRank}.csv'
# if os.path.exists(outputPath):
#     dfTWMVrank = pd.read_csv(outputPath)
#     print("â˜‘ï¸ æª”æ¡ˆå·²å­˜åœ¨ï¼š", outputPath)
# else:
#     # ç¯©é¸ rank < 200
#     dfTWMVrank = dfTWMVmean[dfTWMVmean['rank'] <= 200]

#     # è¼¸å‡ºç¯©é¸çµæœ
#     dfTWMVrank.to_csv(outputPath, index=False, encoding='utf-8')
#     print("âœ… æª”æ¡ˆå­˜å–æˆåŠŸï¼š", outputPath)

# ### æ’ˆå–FindMindçš„èª¿æ•´å¾Œè‚¡åƒ¹è³‡æ–™  => DONE
# outputDir = r'..\data\FinMind\TW\DailyPriceAdj'
# stockList = dfTWMVrank['stock_id'].drop_duplicates().tolist()
# print("ğŸ“¢ å³å°‡æ’ˆå–[æ­·å²ä¿®æ­£è‚¡åƒ¹]è³‡æ–™ï¼Œè‚¡ç¥¨æ¸…å–®çš„é•·åº¦ç‚ºï¼š", len(stockList))
# for stock_id in stockList:
#     outputFile = f'{outputDir}/{sDt.strftime("%Y%m%d")}-{eDt.strftime("%Y%m%d")}/TWDPadj-{stock_id}.csv'
#     if os.path.exists(outputFile):
#         print("â˜‘ï¸ æª”æ¡ˆå·²å­˜åœ¨ï¼š", outputFile)
#     else:
#         os.makedirs(os.path.dirname(outputFile), exist_ok=True)  # ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
#         try:
#             # å˜—è©¦ä¸€æ¬¡æŠ“å…¨éƒ¨è³‡æ–™
#             dfSDA = api.taiwan_stock_daily_adj(
#                 stock_id=stock_id,
#                 start_date=sDt.strftime("%Y-%m-%d"),
#                 end_date=eDt.strftime("%Y-%m-%d")
#             )
#             # å¦‚æœæ²’å ±éŒ¯å°±ç›´æ¥å­˜æª”
#             dfSDA.to_csv(outputFile, index=False, encoding='utf-8-sig')
#             print("âœ… æª”æ¡ˆå­˜å–æˆåŠŸï¼š", outputFile)
#         except Exception as e:
#             print(f"âš ï¸ ä¸€æ¬¡æŠ“å–å¤±æ•—ï¼š{stock_id}ï¼ŒéŒ¯èª¤è¨Šæ¯ï¼š{e}")
#             # åˆ†æ®µå†è©¦
#             try:
#                 # åˆ†æˆå…©æ®µ
#                 midDt = sDt + timedelta(days=365 * 5)
#                 print(f"â¡ï¸ å˜—è©¦åˆ†æ®µæŠ“å– {stock_id} ç¬¬1æ®µï¼š{sDt.date()} ~ {midDt.date()}")
#                 dfSDA1 = api.taiwan_stock_daily_adj(
#                     stock_id=stock_id,
#                     start_date=sDt.strftime("%Y-%m-%d"),
#                     end_date=midDt.strftime("%Y-%m-%d")
#                 )
#                 print(f"â¡ï¸ å˜—è©¦åˆ†æ®µæŠ“å– {stock_id} ç¬¬2æ®µï¼š{(midDt + timedelta(days=1)).date()} ~ {eDt.date()}")
#                 dfSDA2 = api.taiwan_stock_daily_adj(
#                     stock_id=stock_id,
#                     start_date=(midDt + timedelta(days=1)).strftime("%Y-%m-%d"),
#                     end_date=eDt.strftime("%Y-%m-%d")
#                 )
#                 # åˆä½µå…©æ®µ
#                 dfSDA = pd.concat([dfSDA1, dfSDA2], ignore_index=True)
#                 # å„²å­˜
#                 dfSDA.to_csv(outputFile, index=False, encoding='utf-8-sig')
#                 print("âœ… åˆ†æ®µæŠ“å–ä¸¦åˆä½µæˆåŠŸï¼š", outputFile)

#             except Exception as e2:
#                 print(f"âŒ åˆ†æ®µæŠ“å–å¤±æ•—ï¼š{stock_id}ï¼ŒéŒ¯èª¤è¨Šæ¯ï¼š{e2}")
#                 # ä¸è¦ raiseï¼Œç›´æ¥ç¹¼çºŒè·‘ä¸‹ä¸€æ”¯
#                 continue

# ### å°‡æ”¶ç›¤åƒ¹æŒ‰å¹´æ•´ç† => DONE
# # å¹´åº¦ç¯„åœ
# startYear = int(sDt.strftime("%Y"))
# endYear = int(eDt.strftime("%Y"))

# # è³‡æ–™ä¾†æºå’Œç›®æ¨™è³‡æ–™å¤¾
# source_folder = Path(r"..\data\FinMind\TW\DailyPriceAdj\20100101-20201231")
# target_folder = Path(r"..\data\analysis\summary")
# target_folder.mkdir(parents=True, exist_ok=True)

# # é å…ˆå»ºç«‹å¹´ä»½çš„ç©ºæ¸…å–®
# year_data_dict = {year: [] for year in range(startYear, endYear + 1)}

# # å–å¾—æ‰€æœ‰ csv
# csv_files = sorted(source_folder.glob("TWDPadj-*.csv"))
# print("ğŸ“¢ å³å°‡è™•ç†çš„è‚¡åƒ¹è³‡æ–™æª”æ¡ˆæ•¸ï¼š", len(csv_files))

# # éæ­·æ‰€æœ‰æª”æ¡ˆ
# for file in csv_files:
#     print("è®€å–æª”æ¡ˆï¼š", file.name)
#     df = pd.read_csv(file)

#     # åªå– date, stock_id, close
#     df = df.loc[:, ["date", "stock_id", "close"]]

#     # å°‡æ—¥æœŸè½‰æˆ datetime
#     df["date"] = pd.to_datetime(df["date"])

#     # æŒ‰è¡Œåˆ†é…åˆ°å°æ‡‰å¹´ä»½
#     for year in range(startYear, endYear + 1):
#         # ç¯©é¸è©²å¹´ä»½çš„è³‡æ–™
#         df_year = df[df["date"].dt.year == year]
#         if not df_year.empty:
#             year_data_dict[year].append(df_year)

# # è¼¸å‡ºæ¯å¹´æª”æ¡ˆ
# for year in range(startYear, endYear + 1):
#     if year_data_dict[year]:
#         year_df = pd.concat(year_data_dict[year], ignore_index=True)
#         output_file = target_folder / f"closePrice_{year}.csv"
#         if os.path.exists(output_file):
#             print(f"â˜‘ï¸ æª”æ¡ˆå·²å­˜åœ¨ï¼šï¼š{output_file}")
#         else:
#             year_df.to_csv(output_file, index=False, encoding="utf-8-sig")
#             print(f"âœ… æª”æ¡ˆå­˜å–æˆåŠŸï¼š{output_file}")
#     else:
#         print(f"âš ï¸ æ²’æœ‰è³‡æ–™ï¼š{year}")

### è¨ˆç®—è§€å¯ŸæœŸå ±é…¬
target_folder = Path(r"..\data\analysis\momentumNew" + f"/oPeriod{oPeriod}_hPeriod{hPeriod}")
target_folder.mkdir(parents=True, exist_ok=True)
output_file = target_folder / f"observerReturnList{sDt.strftime("%Y%m")}_{eDt.strftime("%Y%m")}.csv"
if os.path.exists(output_file):
    result_df = pd.read_csv(output_file)
    print(f"â˜‘ï¸ æª”æ¡ˆå·²å­˜åœ¨ï¼šï¼š{output_file}")
else:    
    # é å…ˆè®€å–æ‰€æœ‰å¹´åº¦æª”æ¡ˆ
    source_folder = Path(r"..\data\analysis\summary")
    data_by_year = {}
    for year in range(sDt.year, eDt.year + 1):
        file = source_folder / f"closePrice_{year}.csv"
        if file.exists():
            result_df = pd.read_csv(file, parse_dates=["date"])
            data_by_year[year] = result_df
            print(f"å·²è®€å–è³‡æ–™ï¼š{file}")
        else:
            print(f"âš ï¸ æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{file}")

    # çµæœæ¸…å–®
    result_rows = []

    # æ™‚é–“æ¸¸æ¨™
    current_dt = sDt
    while current_dt <= eDt:
        year = current_dt.year
        month = current_dt.month

        df_year = data_by_year.get(year)
        if df_year is not None:
            df_month = df_year[
                (df_year["date"].dt.year == year) &
                (df_year["date"].dt.month == month)
            ]

            grouped = df_month.groupby("stock_id", as_index=False)
            first_trading_days = grouped.apply(lambda g: g.nsmallest(1, "date")).reset_index(drop=True)

            for _, row in first_trading_days.iterrows():
                stock_id = row["stock_id"]
                start_date = row["date"]

                # è¨ˆç®— end_month
                end_month_dt = start_date + relativedelta(months=oPeriod - 1)
                end_year = end_month_dt.year
                end_month = end_month_dt.month

                df_end_year = data_by_year.get(end_year)
                if df_end_year is not None:
                    df_end_month = df_end_year[
                        (df_end_year["stock_id"] == stock_id) &
                        (df_end_year["date"].dt.year == end_year) &
                        (df_end_year["date"].dt.month == end_month)
                    ]

                    if not df_end_month.empty:
                        end_date = df_end_month["date"].max()
                        ED_close = df_end_month[df_end_month["date"] == end_date]["close"].values[0]
                    else:
                        end_date = pd.NaT
                        ED_close = ""
                else:
                    end_date = pd.NaT
                    ED_close = ""

                # çµ„åˆ combination
                comb_start = start_date.strftime("%Y%m")
                comb_end = (start_date + relativedelta(months=oPeriod)).strftime("%Y%m")
                combination = f"{comb_start}-{comb_end}"

                # è¨ˆç®— return
                SD_close = row["close"]
                if ED_close != "":
                    ret = (ED_close - SD_close) / SD_close
                else:
                    ret = ""

                result_rows.append({
                    "stock_id": stock_id,
                    "start_date": start_date.strftime("%Y-%m-%d"),
                    "end_date": end_date.strftime("%Y-%m-%d") if pd.notna(end_date) else "",
                    "SD_close": SD_close,
                    "ED_close": ED_close,
                    "combination": combination,
                    "return": ret
                })

        current_dt += relativedelta(months=1)

    # çµæœDataFrame
    result_df = pd.DataFrame(result_rows)

    # è¼¸å‡º
    result_df.to_csv(output_file, index=False, encoding="utf-8-sig")
    print(f"âœ… å·²è¼¸å‡ºæª”æ¡ˆï¼š{output_file}")

### å¢åŠ å„ç¨®rankç›¸é—œæ¬„ä½
output_file = target_folder / f"observerReturnList{sDt.strftime("%Y%m")}_{eDt.strftime("%Y%m")}-rank.csv"
if os.path.exists(output_file):
    result_df = pd.read_csv(output_file)
    print(f"â˜‘ï¸ æª”æ¡ˆå·²å­˜åœ¨ï¼š{output_file}")
else:
    # ç¢ºä¿ return æ˜¯ float
    result_df["return"] = pd.to_numeric(result_df["return"], errors="coerce")

    # ç™¾åˆ†æ¯”æ’å (0~100)
    def scale_to_0_100(x):
        min_val = x.min()
        max_val = x.max()
        if pd.isna(min_val) or pd.isna(max_val) or max_val == min_val:
            return pd.Series([None] * len(x), index=x.index)
        else:
            return (x - min_val) / (max_val - min_val) * 100

    # è¨ˆç®— RT_%_Rank
    result_df["RT_%_Rank"] = result_df.groupby("combination")["return"].transform(scale_to_0_100)

    # remark åˆå§‹åŒ–
    result_df["remark"] = ""

    # å…ˆæ¨™è¨» exclude
    exclude_mask = (result_df["RT_%_Rank"] > 99.9) | (result_df["RT_%_Rank"] < 0.1)
    result_df.loc[exclude_mask, "remark"] = "exclude"

    # è¨ˆç®— RT_rankï¼Œæ³¨æ„ï¼šä¸å…ˆå‰µæ¬„ä½
    def compute_rt_rank(group):
        mask = group["remark"] != "exclude"
        # åªé‡å°é exclude ç®—æ’å
        ranks = pd.Series(index=group.index, dtype="float")
        ranks.loc[mask] = group.loc[mask, "return"].rank(method="min", ascending=False)
        group["RT_rank"] = ranks
        return group

    result_df = result_df.groupby("combination", group_keys=False).apply(compute_rt_rank)

    # ç¢ºä¿ RT_rank æ˜¯ numeric
    result_df["RT_rank"] = pd.to_numeric(result_df["RT_rank"], errors="coerce")

    # æ›´æ–° remark: winner / loser
    def mark_winner_loser(group):
        valid = group[group["remark"] != "exclude"]
        if valid.empty:
            return group

        n = len(valid)
        top_n = max(1, int(n * 0.1))
        bottom_n = max(1, int(n * 0.1))

        top_threshold = valid.nsmallest(top_n, "RT_rank")["RT_rank"].max()
        bottom_threshold = valid.nlargest(bottom_n, "RT_rank")["RT_rank"].min()

        # åªæ›´æ–° valid éƒ¨åˆ†
        for idx in valid.index:
            rt_rank = group.loc[idx, "RT_rank"]
            if pd.isna(rt_rank):
                continue
            if rt_rank <= top_threshold:
                group.loc[idx, "remark"] = "winner"
            elif rt_rank >= bottom_threshold and rt_rank > top_threshold:
                group.loc[idx, "remark"] = "loser"

        return group

    result_df = result_df.groupby("combination", group_keys=False).apply(mark_winner_loser)

    # è¼¸å‡º
    result_df.to_csv(output_file, index=False, encoding="utf-8-sig")
    print(f"âœ… å·²è¼¸å‡ºæª”æ¡ˆï¼š{output_file}")

### ç”¢ç”Ÿwinner_loseråå–®
output_file = target_folder / f"winner_loser-{sDt.strftime("%Y%m")}_{eDt.strftime("%Y%m")}.csv"
if os.path.exists(output_file):
    filtered_df = pd.read_csv(output_file)
    print(f"â˜‘ï¸ æª”æ¡ˆå·²å­˜åœ¨ï¼š{output_file}")
else:
    # ç¯©é¸ remark ç‚º winner æˆ– loser
    filtered_df = result_df[result_df["remark"].isin(["winner", "loser"])]

    # å­˜æˆæ–°æª”
    filtered_df.to_csv(output_file, index=False, encoding="utf-8-sig")

    print(f"âœ… å·²è¼¸å‡ºæª”æ¡ˆï¼š{output_file}")

### è¨ˆç®—æŒæœ‰æœŸçš„å ±é…¬
output_file = Path(r"..\data\analysis\momentumNew\oPeriod3_hPeriod3\afterwardReturn-201001_202012.csv")
if os.path.exists(output_file):
    filtered_df = pd.read_csv(output_file)
    print(f"â˜‘ï¸ æª”æ¡ˆå·²å­˜åœ¨ï¼š{output_file}")
else:
    price_folder = Path(r"..\data\analysis\summary")

    # æŠŠæ—¥æœŸå­—ä¸²è½‰æˆ datetime
    filtered_df["start_date_dt"] = pd.to_datetime(filtered_df["start_date"])
    filtered_df["end_date_dt"] = pd.to_datetime(filtered_df["end_date"])

    # ç”¨æ–¼å„²å­˜çµæœ
    start_date2_list = []
    SD_close2_list = []
    end_date2_list = []
    ED_close2_list = []

    # è™•ç†æ¯ä¸€åˆ— 
    for idx, row in filtered_df.iterrows():
        stock_id = row["stock_id"]

        # =============== start_date2 ==============
        sd2_month = row["start_date_dt"] + relativedelta(months=+hPeriod)
        sd2_year = sd2_month.year
        sd2_month_num = sd2_month.month

        price_file_sd2 = price_folder / f"closePrice_{sd2_year}.csv"
        try:
            price_df_sd2 = pd.read_csv(price_file_sd2, dtype={"stock_id": str})
            price_df_sd2["date_dt"] = pd.to_datetime(price_df_sd2["date"])

            sd2_candidates = price_df_sd2[
                (price_df_sd2["stock_id"] == stock_id) &
                (price_df_sd2["date_dt"].dt.month == sd2_month_num)
            ]
            if not sd2_candidates.empty:
                sd2_first = sd2_candidates.sort_values("date_dt").iloc[0]
                start_date2 = sd2_first["date"]
                SD_close2 = sd2_first["close"]
            else:
                start_date2 = None
                SD_close2 = None
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{price_file_sd2}ï¼Œå¡«å…¥ None")
            start_date2 = None
            SD_close2 = None

        start_date2_list.append(start_date2)
        SD_close2_list.append(SD_close2)

        # =============== end_date2 ==============
        ed2_month = row["end_date_dt"] + relativedelta(months=+hPeriod)
        ed2_year = ed2_month.year
        ed2_month_num = ed2_month.month

        price_file_ed2 = price_folder / f"closePrice_{ed2_year}.csv"
        try:
            price_df_ed2 = pd.read_csv(price_file_ed2, dtype={"stock_id": str})
            price_df_ed2["date_dt"] = pd.to_datetime(price_df_ed2["date"])

            ed2_candidates = price_df_ed2[
                (price_df_ed2["stock_id"] == stock_id) &
                (price_df_ed2["date_dt"].dt.month == ed2_month_num)
            ]
            if not ed2_candidates.empty:
                ed2_last = ed2_candidates.sort_values("date_dt").iloc[-1]
                end_date2 = ed2_last["date"]
                ED_close2 = ed2_last["close"]
            else:
                end_date2 = None
                ED_close2 = None
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{price_file_ed2}ï¼Œå¡«å…¥ None")
            end_date2 = None
            ED_close2 = None

        end_date2_list.append(end_date2)
        ED_close2_list.append(ED_close2)

    # æ–°å¢æ¬„ä½
    filtered_df["start_date2"] = start_date2_list
    filtered_df["SD_close2"] = SD_close2_list
    filtered_df["end_date2"] = end_date2_list
    filtered_df["ED_close2"] = ED_close2_list

    # è½‰æ•¸å­—
    filtered_df["SD_close2"] = pd.to_numeric(filtered_df["SD_close2"], errors="coerce")
    filtered_df["ED_close2"] = pd.to_numeric(filtered_df["ED_close2"], errors="coerce")

    # è¨ˆç®— return2
    filtered_df["return2"] = (filtered_df["ED_close2"] - filtered_df["SD_close2"]) / filtered_df["SD_close2"]

    # ç§»é™¤ä¸­é–“æ¬„ä½
    filtered_df = filtered_df.drop(columns=["start_date_dt", "end_date_dt"])

    # å­˜æª”
    output_file.parent.mkdir(parents=True, exist_ok=True)
    filtered_df.to_csv(output_file, index=False, encoding="utf-8-sig")

    print(f"âœ… å·²å®Œæˆå¾ŒçºŒå ±é…¬è¨ˆç®—ï¼Œè¼¸å‡ºè‡³ï¼š{output_file}")

### çµ±è¨ˆæŒæœ‰æœŸé–“å¹³å‡å ±é…¬
output_file = Path(r"..\data\analysis\momentumNew\oPeriod3_hPeriod3\afterwardReturn-201001_202012-static.csv")
if os.path.exists(output_file):
    grouped = pd.read_csv(output_file)
    print(f"â˜‘ï¸ æª”æ¡ˆå·²å­˜åœ¨ï¼š{output_file}")
else:
    # ç¢ºä¿ return2 æ˜¯æ•¸å­—å‹æ…‹
    filtered_df["return2"] = pd.to_numeric(filtered_df["return2"], errors="coerce")

    # ä»¥ combination å’Œ remark åˆ†çµ„ï¼Œè¨ˆç®—æ¯çµ„çš„ç­†æ•¸(count)èˆ‡å¹³å‡(mean)
    grouped = (
        filtered_df.groupby(["combination", "remark"], dropna=False)
        .agg(
            count=("return2", "count"),
            mean_return2=("return2", "mean")
        )
        .reset_index()
    )

    # ç§»é™¤ mean_return2 ç‚º NaN çš„çµ„
    grouped = grouped.dropna(subset=["mean_return2"])

    # è¼¸å‡ºçµæœ
    grouped.to_csv(output_file, index=False, encoding="utf-8-sig")

    print(f"âœ… çµ±è¨ˆå·²å®Œæˆï¼Œæª”æ¡ˆè¼¸å‡ºï¼š{output_file}")

### è¨ˆç®—winner - loser
output_file = Path(r"..\data\analysis\momentumNew\oPeriod3_hPeriod3\afterwardReturn-201001_202012-static2.csv")
if os.path.exists(output_file):
    new_df = pd.read_csv(output_file)
    print(f"â˜‘ï¸ æª”æ¡ˆå·²å­˜åœ¨ï¼š{output_file}")
else:
    # ç”¨æ–¼å„²å­˜æ–°çµæœ
    rows = []

    # ä¾ combination åˆ†çµ„
    for comb, group in grouped.groupby("combination"):
        # å…ˆå°‡åŸæœ¬çš„å…©åˆ—æ”¾é€²å»
        for _, row in group.iterrows():
            rows.append(row.to_dict())

        # å–å¾— winner èˆ‡ loser çš„ mean_return2
        winner_row = group[group["remark"] == "winner"]
        loser_row = group[group["remark"] == "loser"]

        if not winner_row.empty and not loser_row.empty:
            winner_mean = winner_row["mean_return2"].values[0]
            loser_mean = loser_row["mean_return2"].values[0]
            diff = winner_mean - loser_mean

            # æ–°å¢ä¸€åˆ—è³‡æ–™
            rows.append({
                "combination": comb,
                "remark": "winner - loser",
                "count": "-",
                "mean_return2": diff
            })

    new_df = pd.DataFrame(rows)
    new_df.to_csv(output_file, index=False, encoding="utf-8-sig")
    print(f"âœ… å·²è¼¸å‡ºæ–°æª”æ¡ˆï¼š{output_file}")

### t-test
output_file = Path(r"..\data\analysis\momentumNew\oPeriod3_hPeriod3\t_test_results.csv")
if os.path.exists(output_file):
    print(f"â˜‘ï¸ æª”æ¡ˆå·²å­˜åœ¨ï¼š{output_file}")
else:
    # ç§»é™¤å¤šé¤˜é€—è™Ÿ
    new_df.columns = new_df.columns.str.strip()

    # å°‡ mean_return2 å»æ‰ % ä¸¦è½‰æˆæ•¸å€¼
    new_df["mean_return2"] = new_df["mean_return2"].str.replace("%", "").astype(float) / 100
    
    results = []

    # åˆ†çµ„ tæª¢å®š
    for remark in ["loser", "winner", "winner - loser"]:
        # å–å‡ºè©² remark è³‡æ–™
        values = new_df.loc[new_df["remark"] == remark, "mean_return2"].dropna().values
        n = len(values)
        if n > 1:
            t_stat, p_value = stats.ttest_1samp(values, popmean=0)
            mean = values.mean()
            results.append({
                "remark": remark,
                "n": n,
                "mean": mean,
                "t_stat": t_stat,
                "p_value": p_value
            })
        else:
            results.append({
                "remark": remark,
                "n": n,
                "mean": values.mean() if n == 1 else None,
                "t_stat": None,
                "p_value": None
            })
    
    result_df = pd.DataFrame(results)
    # print(result_df)

    result_df.to_csv(output_file, index=False, encoding="utf-8-sig")
    print(f"âœ… å·²è¼¸å‡ºçµæœï¼š{output_file}")